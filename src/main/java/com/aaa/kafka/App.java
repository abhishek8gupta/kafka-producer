package com.aaa.kafka;

//import io.confluent.kafka.schemaregistry.client.rest.entities.Schema;

import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;
import java.io.InputStream;
import java.util.Properties;
import org.apache.avro.Schema;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.GenericRecord;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/*
 * This Java source file was generated by the Gradle 'init' task.
 */
public class App {
    private static final Logger LOG = LoggerFactory.getLogger(App.class);
    public String getGreeting() {
        return "Hello world.";
    }

    public static void main(String[] args) throws Exception {
        LOG.info("started ...");
        App app = new App();
        InputStream inputStream = app.getSchemaFile("test_schema.avsc");
        Schema schema = new Schema.Parser().parse(inputStream);
        app.producer(schema);
    }

    private InputStream getSchemaFile(String name) throws Exception{
        InputStream resource = getClass().getClassLoader().getResourceAsStream(name);
        if (resource == null) {
            throw new IllegalArgumentException("file not found!");
        } else {
            return resource;
        }
    }

    void producer(Schema schema) throws Exception {
        String registry = "http://172.20.56.63:8082";
        Properties producerProps = new Properties();
        producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "172.20.56.63:9092");
        producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.IntegerSerializer");
        producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "io.confluent.kafka.serializers.KafkaAvroSerializer");
        producerProps.put(ProducerConfig.ACKS_CONFIG, "1");
        producerProps.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, registry);
        producerProps.put(ProducerConfig.BATCH_SIZE_CONFIG, "16384");
        producerProps.put(ProducerConfig.LINGER_MS_CONFIG, "0");
        producerProps.put(ProducerConfig.BUFFER_MEMORY_CONFIG, "33554432");

        // construct kafka producer.
        Producer<Integer, GenericRecord> producer = new KafkaProducer<Integer, GenericRecord>(producerProps);
// message key.
        int userIdInt = 1;
// message value, avro generic record.
        GenericRecord record = buildRecord(schema);
// send avro message to the topic page-view-event.
        producer.send(new ProducerRecord<Integer, GenericRecord>("PageViewEvent", userIdInt, record));
        producer.flush();
        producer.close();

    }

    public GenericRecord buildRecord(Schema schema) throws Exception{
        // generic record for page-view-event.
        GenericData.Record record = new GenericData.Record(schema);
        // put the elements according to the avro schema.
        record.put("desc", "any-item-id");
        record.put("name", "dbevent1");
        record.put("id", 111);
        return record;
    }
}
